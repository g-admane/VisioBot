{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125e1b62-5280-45e7-8ecb-9a6316145aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No real ports found. Using Dummy Arduino.\n",
      "Initialized dummy serial port: COM0\n",
      "Closing dummy port.\n",
      "Arduino connection closed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "import serial.tools.list_ports\n",
    "import sys, os\n",
    "\n",
    "'''if getattr(sys, 'frozen', False):\n",
    "    # If the application is run as a bundle, the PyInstaller bootloader\n",
    "    # extends the sys module by a flag frozen=True and sets the app \n",
    "    # path into variable _MEIPASS'.\n",
    "    application_path = sys._MEIPASS\n",
    "else:\n",
    "    None\n",
    "    #application_path = os.path.dirname(os.path.abspath(__file__))'''\n",
    "\n",
    "class DummySerial:\n",
    "    def __init__(self, port, baudrate, timeout):\n",
    "        self.port = port\n",
    "        self.baudrate = baudrate\n",
    "        self.timeout = timeout\n",
    "        print(f\"Initialized dummy serial port: {port}\")\n",
    "\n",
    "    def write(self, data):\n",
    "        print(f\"Writing to dummy port: {data}\")\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Closing dummy port.\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to list all available ports\n",
    "def list_ports():\n",
    "    ports = list(serial.tools.list_ports.comports())\n",
    "    for index, p in enumerate(ports):\n",
    "        print(f\"Index = {index}: {p.device} - {p.description}\")\n",
    "    return ports if ports else None\n",
    "\n",
    "# Function to let the user select the port\n",
    "def select_port(ports):\n",
    "    if ports is None:\n",
    "        print(\"No real ports found. Using Dummy Arduino.\")\n",
    "        return DummySerial('COM0', 9600, timeout=1)\n",
    "    while True:\n",
    "        try:\n",
    "            port_index = int(input(\"Enter the index of the Arduino port: \"))\n",
    "            if 0 <= port_index < len(ports):\n",
    "                return ports[port_index].device\n",
    "            else:\n",
    "                print(f\"Invalid index. Please enter a number between 0 and {len(ports)-1}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid integer.\")\n",
    "\n",
    "# List available ports and ask the user to select the Arduino port\n",
    "ports = list_ports()\n",
    "arduino_port = select_port(ports)\n",
    "\n",
    "if isinstance(arduino_port, DummySerial):\n",
    "    arduino = arduino_port\n",
    "else:\n",
    "    try:\n",
    "        arduino = serial.Serial(arduino_port, 9600, timeout=1)\n",
    "        time.sleep(2)  # Allow time for the connection to establish\n",
    "        print(f\"Connected to Arduino on {arduino_port}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Arduino: {e}\")\n",
    "\n",
    "\n",
    "def send_gesture_commands(hand_landmarks, handedness, movement_direction):\n",
    "    # True for Grip, False for Release\n",
    "    grip_status = is_hand_open(hand_landmarks, handedness)\n",
    "    movement_direction = movement_direction\n",
    "    send_combined_commands(grip_status, movement_direction)\n",
    "\n",
    "\n",
    "# Initialize the timers for each movement direction\n",
    "movement_timers = {\"U\": 0, \"D\": 0, \"L\": 0, \"R\": 0}  # Up  # Down  # Left  # Right\n",
    "start_time = None\n",
    "\n",
    "\n",
    "# Function to update the timers based on detected movement directions\n",
    "def update_movement_timers(movement_direction):\n",
    "    for direction in movement_timers:\n",
    "        if direction in movement_direction:\n",
    "            movement_timers[direction] = time.time()\n",
    "        else:\n",
    "            # Check if the direction has been absent for more than 500 ms\n",
    "            if time.time() - movement_timers[direction] > 0.5:\n",
    "                movement_timers[direction] = 0\n",
    "\n",
    "\n",
    "# Function to construct the command string\n",
    "def send_combined_commands(grip, movement_dir):\n",
    "    # Update the timers based on the detected movement directions\n",
    "    update_movement_timers(movement_dir)\n",
    "    # Construct the command string\n",
    "    command_string = f\"G{int(grip)}\"\n",
    "    for direction in \"UDLR\":\n",
    "        command_string += f\"{int(movement_timers[direction] > 0)}\"\n",
    "    command_string += \"\\n\"\n",
    "    print(command_string)  # For debugging or testing\n",
    "    arduino.write(command_string.encode())\n",
    "\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "\n",
    "# Function to determine if the hand is open or closed\n",
    "def is_hand_open(hand_landmarks, handedness):\n",
    "    # Assuming thumb tip is landmark 4 and index finger tip is landmark 8\n",
    "    thumb_tip = hand_landmarks.landmark[4]\n",
    "    index_tip = hand_landmarks.landmark[8]\n",
    "    # Calculate the distance between the thumb tip and index tip in 3D space\n",
    "    distance = np.sqrt((thumb_tip.x - index_tip.x)**2 +\n",
    "                       (thumb_tip.y - index_tip.y)**2 +\n",
    "                       (thumb_tip.z - index_tip.z)**2)\n",
    "    open_hand_threshold = 0.07  # Adjust this threshold based on testing\n",
    "    return distance > open_hand_threshold\n",
    "\n",
    "\n",
    "# Function to determine the direction of hand movement\n",
    "def get_hand_movement_direction(prev_landmark_px,\n",
    "                                curr_landmark_px,\n",
    "                                threshold=6):\n",
    "    delta_x = curr_landmark_px[0] - prev_landmark_px[0]\n",
    "    delta_y = curr_landmark_px[1] - prev_landmark_px[1]\n",
    "    direction = \"\"\n",
    "    if abs(delta_x) > threshold:\n",
    "        direction += \"Left\" if delta_x < 0 else \"Right\"\n",
    "    if abs(delta_y) > threshold:\n",
    "        direction += \"Up\" if delta_y < 0 else \"Down\"\n",
    "    return direction\n",
    "\n",
    "\n",
    "# Capture video from the laptop's webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Variables to store the previous central landmark position\n",
    "prev_landmark_x = None\n",
    "prev_landmark_y = None\n",
    "hand_detected_start_time = None\n",
    "hand_last_seen_time = None  # Initialize the last seen timer\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Convert the BGR image to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "    # Convert the image color back to BGR for OpenCV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    # Draw the hand annotations on the image\n",
    "    if results.multi_hand_landmarks:\n",
    "        if hand_detected_start_time is None:\n",
    "            hand_detected_start_time = time.time()\n",
    "        hand_last_seen_time = time.time()  # Update the last seen time\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                              results.multi_handedness):\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks,\n",
    "                                      mp_hands.HAND_CONNECTIONS)\n",
    "            # Check if hand is open or closed and print the result on the video\n",
    "            hand_status = (\"Release\" if is_hand_open(hand_landmarks,\n",
    "                                                     handedness) else \"Grip\")\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                hand_status,\n",
    "                (image.shape[1] - 200, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "            # Get the central landmark of the hand (e.g., the wrist)\n",
    "            # Wrist as the central point\n",
    "            curr_landmark = hand_landmarks.landmark[0]\n",
    "            if prev_landmark_x is not None and prev_landmark_y is not None:\n",
    "                # Convert landmark positions to relative pixel coordinates\n",
    "                frame_height, frame_width, _ = image.shape\n",
    "                prev_landmark_px = np.array([\n",
    "                    prev_landmark_x * frame_width,\n",
    "                    prev_landmark_y * frame_height\n",
    "                ])\n",
    "                curr_landmark_px = np.array([\n",
    "                    curr_landmark.x * frame_width,\n",
    "                    curr_landmark.y * frame_height\n",
    "                ])\n",
    "                # Determine the direction of movement\n",
    "                movement_direction = get_hand_movement_direction(\n",
    "                    prev_landmark_px, curr_landmark_px)\n",
    "                print(\"movement_direction = \", movement_direction)\n",
    "                # Check if the hand has been present for more than 5 seconds\n",
    "                if hand_detected_start_time and (time.time() -\n",
    "                                                 hand_detected_start_time > 5):\n",
    "                    send_gesture_commands(hand_landmarks, handedness,\n",
    "                                          movement_direction)\n",
    "                cv2.putText(\n",
    "                    image,\n",
    "                    movement_direction,\n",
    "                    (image.shape[1] - 200, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 0, 255),\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "                tips = [hand_landmarks.landmark[i] for i in [4, 8, 12, 16, 20]]\n",
    "                palm_base = hand_landmarks.landmark[0]\n",
    "                M_F = 0.167\n",
    "                # Calculate the distance from each finger tip to the palm base\n",
    "                distances_mf = [\n",
    "                    np.sqrt((tip.x - palm_base.x)**2 +\n",
    "                            (tip.y - palm_base.y)**2 +\n",
    "                            (tip.z - palm_base.z)**2) for tip in tips\n",
    "                ]\n",
    "                # Check if the index, ring, and pinky finger tips are closer to the palm base\n",
    "                # and the mf tip is far from the base\n",
    "                if all(distances_mf[i] + M_F < distances_mf[2]\n",
    "                       for i in [1, 3, 4]):\n",
    "                    if start_time is None:\n",
    "                        start_time = time.time()\n",
    "                    elif time.time() - start_time > 3:\n",
    "                        cv2.putText(\n",
    "                            image,\n",
    "                            \"F**k YOU TOO BITCH ASS NIGGA!!!\",\n",
    "                            (50, 250),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.75,\n",
    "                            (230, 216, 173),\n",
    "                            2,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "                    #else:\n",
    "                    #start_time = None\n",
    "            # Update the previous landmark positions\n",
    "            prev_landmark_x = curr_landmark.x\n",
    "            prev_landmark_y = curr_landmark.y\n",
    "    else:\n",
    "        # Check if the hand has been absent for more than 1 second\n",
    "        if hand_last_seen_time and (time.time() - hand_last_seen_time > 1):\n",
    "            hand_detected_start_time = None  # Reset the timer\n",
    "    cv2.namedWindow(\"VisioBot\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"VisioBot\", image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord(\"q\"or \"Q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "hands.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "arduino.close()\n",
    "print(\"Arduino connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b9f96-2252-4558-8f00-e73c3330ac2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093a2d5-dea7-47e0-97ae-60b7b8253f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
